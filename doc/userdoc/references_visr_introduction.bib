% Encoding: UTF-8

@Article{tut-coleman_et_al2018_an_audio-visual_system_for_object_based_audio,
  author    = {Coleman, Philip and Franck, Andreas and Francombe, Jon and others},
  title     = {An Audio-Visual System for Object-Based Audio: {From} Recording to Listening},
  journal   = {IEEE Transactions on Multimedia},
  year      = {2018},
  owner     = {af5u13},
  timestamp = {2017.12.29},
}

@Article{tut-pulkki1997_virtual_sound_source_positioning_using_vector_base_amplitude_panning,
  author    = {Pulkki, Ville},
  title     = {Virtual Sound Source Positioning Using Vector Base Amplitude Panning},
  journal   = {Journal of the Audio Engineering Society},
  year      = {1997},
  volume    = {45},
  number    = {6},
  pages     = {456-466},
  month     = jun,
  file      = {pulkki1997_virtual_sound_source_positioning_using_vector_base_amplitude_panning.pdf:documents/spatial_audio/pulkki1997_virtual_sound_source_positioning_using_vector_base_amplitude_panning.pdf:PDF},
  owner     = {af5u13},
  timestamp = {2014.11.02},
  url       = {http://www.aes.org/e-lib/browse.cfm?elib=7853},
}

@Article{tut-diamond_boyd2016_cvxpy,
  author  = {Diamond, Steven and Boyd, Stephen},
  title   = {{CVXPY}: A {P}ython-Embedded Modeling Language for Convex Optimization},
  journal = {J. Mach. Learn. Res.},
  year    = {2016},
  volume  = {17},
  number  = {83},
  pages   = {1--5},
  note    = {\url{http://www.cvxpy.org}},
}

@InProceedings{tut-pike_melchior_tew2014_assessing_the_plausibility_of_non-individualised_dynamic_binaural_synthesis_in_a_small_room,
  author    = {Pike, Chris and Melchior, Frank and Tew, Tony},
  title     = {Assessing the Plausibility of Non-Individualised Dynamic Binaural Synthesis in a Small Room},
  booktitle = {AES 55th Int. Conf. Spatial Audio},
  year      = {2014},
  address   = {Helsinki, Finland},
  month     = aug,
  owner     = {fnk},
  timestamp = {2014.09.03},
}

@Article{tut-mackensen_et_al1999_binaural_room_scanning_a_new_tool_for_acoustic_and_psychoacoustic_research,
  author    = {Mackensen,Philip and Felderhof,Uwe and Theile, G\"{u}nther and others},
  title     = {Binaural room scanning --- A new tool for acoustic and psychoacoustic research},
  journal   = {J. Acoust. Soc. Amer.},
  year      = {1999},
  volume    = {105},
  number    = {2},
  pages     = {1343-1344},
  owner     = {af5u13},
  timestamp = {2017.11.28},
}

@InProceedings{tut-pike_romanov2017_an_impulse_response_dataset_for_dynamic_data-based_auralization_of_advanced_sound_systems,
  author    = {Pike, Chris and Romanov, Michael},
  title     = {An Impulse Response Dataset for Dynamic Data-Based Auralization of Advanced Sound Systems},
  booktitle = {Proc. Audio Eng. Soc. 142nd Conv.},
  year      = {2017},
  address   = {Berlin, Germany},
  month     = may,
  note      = {{Engineering Brief}},
  url       = {http://www.aes.org/e-lib/browse.cfm?elib=18709},
}

@Misc{tut-pybind11,
  author = {Jakob, Wenzel and Rhinelander, Jason and Moldovan, Dean},
  title  = {pybind11 â€” Seamless operability between C++11 and Python},
  year   = {2016},
  note   = {https://github.com/pybind/pybind11},
}

@InProceedings{tut-hughes_et_al2018_dual_frequency_amplitude_panning_for_multichannel_audio_systems,
  author    = {Hughes, Richard James and Franck, Andreas and Cox, Trevor J. and Shirley, Ben G. and Fazi, Filippo Maria},
  title     = {Dual frequency band amplitude panning for multichannel audio systems},
  booktitle = {Proc. AES Int. Conf Sound Reproduction},
  year      = {2018},
  address   = {Tokyo, Japan},
  month     = aug,
}

@InProceedings{tut-franck_et_al2018_an_open_realtime_binaural_synthesis_toolkit_for_audio_research,
  author    = {Franck, Andreas and Costantini, Giacomo and Pike, Chris and Fazi, Filippo Maria},
  title     = {An Open Realtime Binaural Synthesis Toolkit for Audio Research},
  booktitle = {Proc. Audio Eng. Soc. 144th Conv.},
  year      = {2018},
  address   = {Milano, Italy},
  month     = may,
  note      = {{Engineering Brief}},
}

@Misc{tut-itu2015-itu-r-bs1534-3,
  author = {ITU},
  title  = {ITU-R BS.1534-3, Method for the subjective assessment of intermediate quality levels of coding systems},
  year   = {2015},
}

@Misc{tut-franck2018_visr_tutorial_source_code,
  author       = {Franck, Andreas},
  title        = {VISR tutorial examples},
  howpublished = {Source code},
  month        = aug,
  year         = {2018},
  note         = {{DOI}: \href{http://dx.doi.org/10.15126/surreydata.XXXXXXX}{10.15126/surreydata.XXXXXXX}},
}

@Misc{tut-s3a2018_visr_download_site,
  title        = {VISR download web site},
  howpublished = {\url{http://cvssp.org/data/s3a/public/VISR/}},
  month        = aug,
  year         = {2018},
}

@Article{tut-franck_wang_fazi2017_sparse_l1-optimal_multiloudspeaker_panning_and_its_equivalence_to_vector_based_amplitude_panning,
  author    = {Franck, Andreas and Wang, Wenwu and Fazi, Filippo Maria},
  title     = {Sparse, {$\ell_{1}$}-Optimal Multi-Loudspeaker Panning and its Relation to Vector Base Amplitude Panning},
  journal   = {IEEE Transactions on Audio, Speech, and Language Processing},
  year      = {2017},
  volume    = {25},
  number    = {5},
  pages     = {996-1010},
  month     = may,
  owner     = {af5u13},
  timestamp = {2016.04.06},
}

@Article{tut-oliphant2007_python_for_scientific_computing,
  author   = {Oliphant, Travis E.},
  title    = {Python for Scientific Computing},
  journal  = {Computing in Science Engineering},
  year     = {2007},
  volume   = {9},
  number   = {3},
  pages    = {10-20},
  month    = may,
  keywords = {high level languages;Python;high-level language;scientific codes;scientific computing;steering language;Application software;Embedded software;High level languages;Internet;Libraries;Prototypes;Scientific computing;Software standards;Standards development;Writing;Python;computer languages;scientific computing;scientific programming},
}

@Article{tut-wilson_et_al2014_best_practices_for_scientific_computing,
  author    = {Greg Wilson and Aruliah, D. A. and Brown, C and others},
  title     = {Best Practices for Scientific Computing},
  journal   = {{PLoS} Biology},
  year      = {2014},
  volume    = {12},
  number    = {1},
  pages     = {e1001745},
  month     = jan,
  editor    = {Jonathan A. Eisen},
  file      = {:documents/software/wilson_et_al2014_best_practices_for_scientific_computing.pdf:PDF},
  owner     = {af5u13},
  publisher = {Public Library of Science ({PLoS})},
  timestamp = {2017.03.10},
}

@InProceedings{tut-cannam_figueira_plumbley2012_sound_software_towards_software_research_in_audio_and_music_research,
  author    = {Cannam, Chris and Figueira, Lu\'{\i}s and Plumbley, Mark D.},
  title     = {Sound Software: Towards Software Reuse in Audio and Music Research},
  booktitle = {IEEE Int. Conf. Acoust., Speech Signal Process.},
  year      = {2012},
  pages     = {2745-2748},
  month     = mar,
  file      = {cannam_figueira_plumbley2012_sound_software_towards_software_research_in_audio_and_music_research.pdf:documents/software/cannam_figueira_plumbley2012_sound_software_towards_software_research_in_audio_and_music_research.pdf:PDF},
  keywords  = {music;software reusability;audio research;music research;software development;software reuse;sound software;Collaboration;Communities;Educational institutions;Multiple signal classification;Software reusability;Training;Programming;Reproducible research;Scientific computing;Software reuse;Software tools},
  owner     = {af5u13},
  timestamp = {2017.03.09},
}

@InProceedings{tut-geier_hohn_spors2012_an_open-source_c++_framework_for_multithreaded_realtime_multichannel_applications,
  author    = {Geier, Matthias and Hohn, Torben and Spors, Sascha},
  title     = {An Open-Source {C++} Framework for Multithreaded Realtime Multichannel Audio Applications},
  booktitle = {Proc. Linux Audio Conf.},
  year      = {2012},
  pages     = {183-188},
  address   = {Stanford, California, USA},
  month     = apr,
  file      = {geier_hohn_spors2012_an_open-source_c++_framework_for_multithreaded_realtime_multichannel_applications.pdf:documents/geier_hohn_spors2012_an_open-source_c++_framework_for_multithreaded_realtime_multichannel_applications.pdf:PDF},
  owner     = {af5u13},
  timestamp = {2014.10.03},
}

@InProceedings{tut-carpentier_noisternig_warusfel2015_twenty_years_of_ircam_spat_looking_back_looking_forward,
  author    = {Carpentier, Thibaut and Noisternig, Markus and Warusfel, Olivier},
  title     = {Twenty Years of Ircam {Spat}: Looking Back, Looking Forward},
  booktitle = {Proc. Int. Computer Music Conf.},
  year      = {2015},
  address   = {Denton, TX, USA},
  month     = sep,
}

@Article{tut-amatriain_arumi_garcia2008_a_platform_for_efficient_and_rapid_development_of_cross_platform_audio_applications,
  author   = {Amatriain, Xavier and Arumi, Pau and Garcia, David},
  title    = {A framework for efficient and rapid development of cross-platform audio applications},
  journal  = {Multimedia Systems},
  year     = {2008},
  volume   = {14},
  number   = {1},
  pages    = {15-32},
  month    = jun,
  abstract = {In this article, we present CLAM, a C++ software framework, that offers a complete development and research platform for the audio and music domain. It offers an abstract model for audio systems and includes a repository of processing algorithms and data types as well as all the necessary tools for audio and control input/output. The framework offers tools that enable the exploitation of all these features to easily build cross-platform applications or rapid prototypes for media processing algorithms and systems. Furthermore, included ready-to-use applications can be used for tasks such as audio analysis/synthesis, plug-in development, feature extraction or metadata annotation. CLAM represents a step forward over other similar existing environments in the multimedia domain. Nevertheless, it also shares models and constructs with many of those. These commonalities are expressed in the form of a metamodel for multimedia processing systems and a design pattern language.},
  day      = {01},
  file     = {:documents/software/amatriain_arumi_garcia2008_a_platform_for_efficient_and_rapid_development_of_cross_platform_audio_applications.pdf:PDF},
  url      = {https://doi.org/10.1007/s00530-007-0109-6},
}

@Book{tut-boulanger2000_the_csound_book,
  title     = {The Csound Book},
  publisher = {MIT Press},
  year      = {2000},
  editor    = {Boulanger, Richard Charles},
  owner     = {af5u13},
  timestamp = {2017.03.14},
}

@Book{tut-wilson_cottle_collins2011_the_supercollider_book,
  title     = {The SuperCollider Book},
  publisher = {MIT Press},
  year      = {2011},
  author    = {Wilson, Scott and Cottle, David and Collins, Nick},
}

@Article{tut-orlarey_fober_letz2004_syntactical_and_semantic_aspects_of_faust,
  author    = {Orlarey, Yann and Fober, Dominique and Letz, St\'{e}phane},
  title     = {Syntactical and semantical aspects of {Faust}},
  journal   = {Soft Computing},
  year      = {2004},
  volume    = {8},
  number    = {9},
  pages     = {623--632},
  abstract  = {This paper presents some syntactical and semantical aspects of FAUST (Functional AUdio STreams), a programming language for real-time sound processing and synthesis. The programming model of FAUST combines two approaches: functional programming and block-diagrams composition. It is based on a block-diagram algebra. It as a well defined formal semantic and can be compiled into efficient C/C++ code.},
  file      = {orlarey_fober_letz2004_syntactical_and_semantic_aspects_of_faust.pdf:documents\\software\\orlarey_fober_letz2004_syntactical_and_semantic_aspects_of_faust.pdf:PDF},
  owner     = {af5u13},
  timestamp = {2017.03.14},
}

@Misc{tut-itu2017-itu-r-bs2051-1,
  author = {ITU},
  title  = {ITU-R BS.2051-1, Advanced sound system for programme production},
  year   = {2017},
}

@Comment{jabref-meta: databaseType:bibtex;}

@comment{BibDesk Static Groups{
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<array>
	<dict>
		<key>group name</key>
		<string>Not yet</string>
		<key>keys</key>
		<string></string>
	</dict>
</array>
</plist>
}}
